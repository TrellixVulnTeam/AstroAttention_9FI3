{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Pre-Trained Model\n",
    "Load in a model(s) of your choice and evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#Data\n",
    "from FRDEEP import FRDEEPF\n",
    "\n",
    "#My Functions / Models\n",
    "from models_new import *\n",
    "#from evaluations import *\n",
    "\n",
    "#Other\n",
    "import PIL\n",
    "from torchsummary import summary\n",
    "from models.networks_other import init_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model(s?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'playground' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-254f89b74a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mnet_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'playgound'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#net = transfer_original(); net_name = 'transfer_original'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#net = AGSononet(); net_name = 'AGSononet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#net = AGTransfer(); net_name = 'AGTransfer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'playground' is not defined"
     ]
    }
   ],
   "source": [
    "net = playground(); net_name = 'playgound'\n",
    "#net = transfer_original(); net_name = 'transfer_original'\n",
    "#net = AGSononet(); net_name = 'AGSononet'\n",
    "#net = AGTransfer(); net_name = 'AGTransfer'\n",
    "\n",
    "# Put network on device defined previously.\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which model should be read in:\n",
    "\n",
    "(custom name or convention based on parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters of Trained Network:\n",
    "date = '0211' #format: mmdd\n",
    "lr = 0.1\n",
    "Epoch = 180\n",
    "\n",
    "\n",
    "#Custom Name:\n",
    "use_name = True\n",
    "custom_file_name = 'Playground-0211-0.1_180Epochs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_name:\n",
    "    ckpt_name = custom_file_name+'.pt'\n",
    "else:\n",
    "    ckpt_name = f'{net_name}-{date}-{lr}_{Epoch}Epochs.pt'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device to be used:\\t>> {device}\")\n",
    "print(f\"\"\"Designated Model:\\t>> {ckpt_name}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(f'TrainedNetworks/{ckpt_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ignite.metrics\n",
    "classes = ['FRI','FRII']\n",
    "conf_mat = np.zeros((2,2))\n",
    "correct , total = 0 , 0\n",
    "net.eval()\n",
    "test_results = 0 #forces an except for first iteration.\n",
    "\n",
    "for epoch_count in range(Epoch):\n",
    "    with torch.no_grad():\n",
    "        for data in testset:\n",
    "            X , y = data\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = net.forward(X)\n",
    "            \n",
    "            try:\n",
    "                test_results = np.append(test_results,torch.argmax(output,1).cpu().numpy(),axis=0)\n",
    "                test_labels  = np.append(test_labels,y.cpu().numpy(),axis=0)\n",
    "                test_raw_results = np.append(test_raw_results,output.cpu().numpy(),axis=0)\n",
    "            except:\n",
    "                test_results = torch.argmax(output,axis=1).cpu().numpy()\n",
    "                test_labels  = y.cpu().numpy()\n",
    "                test_raw_results = output.cpu().numpy()\n",
    "                #print(f'y={y.shape}{y}\\n output={output.cpu().numpy().shape}{output}\\n output_saved={test_results.shape}{test_results}')\n",
    "                #print('\\n\\ny\\tsaved\\tout')\n",
    "                #for i in range(int(y.cpu().numpy().shape[0])):\n",
    "                #    print(f'{y[i]}\\t{test_results[i]}\\t{output.cpu().numpy()[i]}\\t{test_raw_results[i]}\\n')\n",
    "                \n",
    "            for idx, i in enumerate(output):\n",
    "                conf_mat[y[idx],int(torch.argmax(i))]+=1\n",
    "\n",
    "accuracy = (conf_mat[0,0]+conf_mat[1,1])/conf_mat.sum()*100\n",
    "total = int(conf_mat.sum())\n",
    "correct = int(conf_mat[0,0]+conf_mat[1,1])\n",
    "print(f\"Accuracy of Model on test set: {accuracy:.1f}% ({correct} out of {total})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
